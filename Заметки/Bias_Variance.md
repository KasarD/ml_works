## Bias/Variance (K-fold метод)
**Хорошо написано [тут](http://scott.fortmann-roe.com/docs/BiasVariance.html)**

Ошибки в моделях классификации или предсказания могут быть вызваны смещением (**bias**) и разбросом (**variance**) данных, на которых проводится эксперимент. Вследствие чего возможны случаи, когда модель тренируется на довольно узкой области данных, а работа происходит на широкой области.

Сразу заметим, что, вообще говоря, мы имеем дело только с одной моделью в ед. времени. С другой стороны, мы можем построить много моделей с одинаковой структурой, но обучать их на слегка разных наборах данных (например, разделять тренировочный/валидационный набор в разных пропорциях). Именно для таких случаев рассматриваются следующие критерии:
1. **Ошибка смещения**. Показывает, насколько сильно различается предсказанное моделью значение от ожидаемого. Например, если мы предсказываем вероятность ухода клиента из банка, и сеть предсказала 70%, а на самом деле он ушел со 100% вероятностью, то ошибка смещения составит 30%.
2. **Ошибка разброса**. Берем конкретую точку валидационного набора данных и прогоняем её через все модели сети (которые обучались на слегка разных данных). Ошибкой разброса называется изменение предсказанного значения каждой из сетей относительно выбранной точки.

- Стоит отметить, что ошибка **смещения** проявляется при недостаточном количестве данных (размерность набора исчисляется в сотнях). Когда же тренировочный набор разрастается, смещение относительно центра падает. 
- Для **разброса** важна сложность модели. Чем она выше (то есть, чем больше параметров подается на вход модели), тем смещение меньше, а разброс больше. Графический результат представлен ниже
![Bias vs Variance](http://scott.fortmann-roe.com/docs/docs/BiasVariance/biasvariance.png)

## K-fold cross-validation метод
Для проверки нашей модели на предмет оценки смещения и разброса применим трюк *k-fold cross-validation*. Суть данного метода заключается в том, что весь тренировочный набор данных разбивается на k частей, после чего сеть тренируется k раз, причем, каждая новая итерация обучения происходит на k-1 наборах данных, а валидация на наборе ki.
Таким образом, модель тренируется k раз и каждый раз выбранная нами метрика (точность) валидируется на новом уникальном наборе ki.
- Отметим, что высокий разброс (variance) свидетельствует о том, что сеть **переобучена** (overfitting). В таком случае, необходимо применить технику регуляризации обучения модели (например, *Dropout regularization*)

**Подробнее [тут](https://machinelearningmastery.com/k-fold-cross-validation/)**